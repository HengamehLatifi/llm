<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: lib.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: lib.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/** @module lib */

// This code provides functions to initialize connections, handle model selection, and manage the execution of text completion tasks based on user inputs. 

import "colors"
import { MODELS } from "./constants.js"
import fs from "fs"
import dotenv from "dotenv"
import child_process from "child_process"
import { escapeShell, concatPath } from "./utils.js"
import { useOpenai, useOpenaiChat } from "./apis/openai/api.js"
import { useBing } from "./apis/bing/api.js"
import { useHuggingface } from "./apis/huggingface/api.js"
import { $ } from "zx"

/**
 * @type {boolean}
 */
$.verbose = false
dotenv.config()

// directory of this file
/**
 * Intended to hold the directory path of the current module.
 * @type {string}
 */
let __dirname = new URL(".", import.meta.url).pathname

// if windows
/**
 * If the operating system is windows then modifies the `__dirname` path format specifically for compatibility reasons on Windows systems.
 */
const isWindows = process.platform === "win32"
if (isWindows) {
  // /C:/ -> /c/
  __dirname = __dirname.replace(/^\/([A-Z]):/, (match, p1) => {
    return "/" + p1.toLowerCase()
  })
}

/**
 * Manages interactions with different language models for generating text completions based on given prompts.
 * Reading Prompts from Files. 
 * Setting Default Values for `temperature`, `system`, `model`, and `backoff` if they are not provided in the arguments.
 * Model Selection and Validation.
 * Inside `getCompletion`, an internal function, it generates outputs based on the specified model.
 * Includes error handling for network-related issues.
 * Interpreting: Processes a prompt to execute specific instructions within the prompt text.
 * Chaining: Chaining of outputs where the output of one prompt feeds into another.
 * Plugins: Processes prompts using external tools (like curl).
 * Output Handling: Based on the quiet and verbose flags, 
 * @function
 * @param {object} args 
 * @returns {string}
 */
export async function useLlm(args) {
  if (args.file === true) {
    args.prompt = fs.readFileSync(args.prompt, "utf8")
  } else if (typeof args.file === "string") {
    args.prompt = fs.readFileSync(args.file, "utf8")
  }

  args.temperature = args.temperature ?? 0
  args.system = args.system ?? ""
  args.model = args.model ?? "gpt-3.5-turbo-0613"
  args.backoff = args.backoff ?? 2000

  let modelDescriptor
  if (MODELS[args.model]) {
    modelDescriptor = MODELS[args.model]
  } else if (args.model.startsWith("gpt-")) {
    modelDescriptor = {
      kind: "openai-chat",
    }
  } else {
    try {
      child_process.execSync(
        `python ${concatPath(
          __dirname,
          "apis/huggingface/check.py"
        )} "${escapeShell(args.model)}"`,
        {
          stdio: "inherit",
          cwd: __dirname,
        }
      )
      if (!args.quiet)
        console.log(`Using ${args.model.yellow} from huggingface.`)
      modelDescriptor = {
        kind: "huggingface",
      }
    } catch (e) {
      if (!args.quiet) console.log(`Model ${args.model} not found`)
      console.log(e)
      process.exit(1)
    }
  }

  const getCompletion = async (args) => {
    let completion
    let print = (data) => process.stdout.write(data)
    if (args.silent === true) print = () => {}
    try {
      switch (modelDescriptor.kind) {
        case "huggingface":
          completion = await useHuggingface({ print, args })
          break
        case "openai":
          completion = await useOpenai({ print, args })
          break
        case "openai-chat":
          completion = await useOpenaiChat({ print, args })
          break
        case "bing":
        case "bing-creative":
        case "bing-balanced":
        case "bing-precise":
          completion = await useBing({ print, args })
          break
        case "wlm":
        case "wizardlm-7b-uncensored":
          if (!args.modelWasSet) {
            args.model = "WizardLM-7B-Uncensored/ggml-model-q4_0.gguf"
            args.modelContextSize = 4096
            args.modelWasSet = true
          }
        case "wlm13":
        case "wizardlm-13b":
          if (!args.modelWasSet) {
            args.model =
              "WizardLM-1.0-Uncensored-Llama2-13b/ggml-model-q4_0.gguf"
            args.modelContextSize = 2048
            args.modelWasSet = true
          }
        case "__wizardlm-anymodel__":
          const randInt = Math.floor(Math.random() * 1000000)
          const promptPath = `/tmp/llm-prompt.tmp.${randInt}`
          await fs.promises.writeFile(promptPath, args.prompt)
          const basePath = "/Users/snwfdhmp/Dev/workspaces/ai"
          completion =
            await $`${basePath}/llama.cpp-custom/main -f "${promptPath}" -m ${basePath}/models/${args.model} -n -2 -c ${args.modelContextSize} -ngl 1 2>/dev/null`
          completion = completion.stdout
            .slice(1 + args.prompt.length)
            .trimStart()
          print(completion)
          await fs.promises.unlink(promptPath)
          break
        default:
          console.log(`model ${args.model} is known but not supported yet`)
          process.exit(1)
          break
      }
    } catch (e) {
      // handle network errors with backoff
      const errorHandlers = [
        { code: 429, message: "too many requests" },
        { code: 503, message: "service unavailable" },
        { code: 502, message: "bad gateway" },
      ]
      for (const errorHandler of errorHandlers) {
        if (!e.message.includes(`${errorHandler.code}`)) continue
        if (!args.quiet)
          console.log(
            `getCompletion: ${errorHandler.message} (${errorHandler.code}), waiting ${args.backoff}ms`
          )
        await new Promise((resolve) => setTimeout(resolve, args.backoff))
        return await getCompletion({ ...args, backoff: args.backoff * 2 })
      }

      // default error handler
      console.error(`Error: ${e.message}`)
      console.log(e)
      return
    }
    return completion
  }

  if (args.interpret) {
    let vars = args.vars || {}
    const processFile = async (prompt) => {
      const runInstructions = prompt.match(/&lt;\|@(run.*)\|>/g) // these regex should be identical except the ()
      const parts = prompt.split(/&lt;\|@run.*\|>/g) // these regex should be identical except the ()
      parts.pop()
      let total = ""
      for (let i = 0; i &lt; parts.length; i++) {
        // detect &lt;|$var|> pattern
        const matches = parts[i].match(/&lt;\|\$.*?\|>/g)
        const unique = [...new Set(matches)]
        for (let j = 0; j &lt; unique.length; j++) {
          // replace var with value
          const varName = unique[j].slice(3, -2)
          const varValue = vars[varName]
          if (varValue === undefined) {
            console.log(`Variable ${varName} not found`)
            process.exit(1)
          }
          parts[i] = parts[i].replace(unique[j], varValue)
        }

        const prompt = total + parts[i]
        // console.log(`Running '''${prompt}'''`)
        const completion = await getCompletion({
          ...args,
          prompt,
        })
        total = prompt + completion

        const runInstruction = runInstructions[i].slice(3).slice(0, -2)
        if (runInstruction === "run") continue
        if (runInstruction.split(" ").includes("replace")) total = completion
      }
      return total
    }
    return await processFile(args.prompt)
  } else if (args.chain) {
    const processFile = async (file, silent) => {
      // detect &lt;|@var|> pattern
      const matches = file.match(/&lt;\|@.*?\|>/g)
      const unique = [...new Set(matches)]
      for (let i = 0; i &lt; unique.length; i++) {
        // process subfile
        const output = await processFile(
          fs.readFileSync(`./${unique[i].slice(3, -2)}.txt`, "utf-8"),
          true
        )
        file = file.replace(unique[i], output)
      }
      return await getCompletion({
        ...args,
        prompt: file,
        silent: silent &amp;&amp; args.quiet,
      })
    }
    return await processFile(args.prompt, false)
  } else if (args.plugins) {
    const curlPath = child_process
      .execSync("which curl", {
        encoding: "utf8",
      })
      .trim()
    if (!curlPath) {
      console.error(
        "curl is not available. Please install curl to use plugins."
      )
      process.exit(1)
    }
    if (!args.quiet) console.log("Plugins enabled")

    const compileAndRun = async (path, variables) => {
      const file = fs.readFileSync(path, "utf8")
      const regex = /&lt;\|\$(.*)\|>/g
      const compiled = file.replace(regex, (_, variable) => {
        if (variables[variable]) {
          return variables[variable]
        } else {
          throw new Error(`Variable ${variable} not found`)
        }
      })
      return await getCompletion({
        ...args,
        prompt: compiled,
        silent: !args.verbose,
      })
    }

    const prompt = args.prompt
    const step1Output = await compileAndRun(
      concatPath(__dirname, "/plugins/plugin_prompt--step1.txt"),
      {
        prompt,
      }
    )
    const regexpOutput = /&lt;\|output\.start\|>([\s\S]*)&lt;\|output\.end\|>/
    if (!step1Output.match(regexpOutput)) {
      console.log(step1Output)
      process.exit(0)
    }
    const [_, output] = regexpOutput.exec(step1Output)
    const regexpPlugin =
      /&lt;\|plugins\["(.*)"\]\.([a-zA-Z0-9_]+)\|>(.*)&lt;\|plugins\.end\|>/

    const [__, plugin, fn, payload] = regexpPlugin.exec(output)
    console.log(`${`Using plugin: ${plugin}.${fn}`.blue} ${payload}`)

    const regexpCurl = /&lt;\|curl\.start\|>(.*)&lt;\|curl\.end\|>/
    let [___, curlCommand] = regexpCurl.exec(output)

    if (
      !curlCommand.trim().startsWith("curl") ||
      !curlCommand.trim().split("\n").length > 1
    ) {
      console.log("panic: does not look like a curl command")
      console.log("\n\n\t" + curlCommand.trim() + "\n\n")
      process.exit(1)
    }
    let result
    try {
      curlCommand =
        curlCommand.trim().replace(/^curl/, `"${curlPath}"`) +
        " -s -H 'WebPilot-Friend-UID: snwfdhmp'"
      // put url at the end
      const url = curlCommand.match(/"https?:\/\/[^\s]+"/g)
      if (!url) {
        console.log("panic: does not look like a curl command")
        console.log("\n\n\t" + curlCommand.trim() + "\n\n")
        process.exit(1)
      }
      curlCommand = curlCommand.replace(url[0], "")
      curlCommand = curlCommand + " " + url[0]
      result = child_process.execSync(curlCommand).toString()
    } catch (e) {
      console.log("Error while executing curl command")
      console.log(e)
      if (e.stdout) {
        console.log(e.stdout.toString())
      }
      if (e.stderr) {
        console.log(e.stderr.toString())
      }
      process.exit(1)
    }

    // curl to axios

    const finalOutput = await compileAndRun(
      concatPath(__dirname, "/plugins/plugin_prompt--step2.txt"),
      {
        pluginsOutput: JSON.stringify({
          plugin,
          fn,
          payload,
          output: result,
        }),
        prompt,
      }
    )

    const userOutput = regexpOutput.exec(finalOutput)
    if (!args.verbose) {
      if (!userOutput) {
        console.log(finalOutput.trim())
      } else {
        console.log(userOutput[1].trim())
      }
    }
    return userOutput
  } else {
    return await getCompletion(args)
  }
}

/**
 * Is a simplified wrapper for the `useLlm` function and streamlines the use of `useLlm` by pre-setting certain parameters for silent operation.
 * @param {string} prompt 
 * @param {object} options 
 * @returns {string}
 */
export const llm = async (prompt, options) => {
  return await useLlm({ prompt, quiet: true, silent: true, ...options })
}
</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Modules</h3><ul><li><a href="module-Bing.html">Bing</a></li><li><a href="module-constants.html">constants</a></li><li><a href="module-HuggingFace.html">HuggingFace</a></li><li><a href="module-lib.html">lib</a></li><li><a href="module-main.html">main</a></li><li><a href="module-OpenAI.html">OpenAI</a></li><li><a href="module-utils.html">utils</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc/jsdoc">JSDoc 3.6.7</a> on Mon May 13 2024 15:08:58 GMT+0000 (Coordinated Universal Time)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
